#Generated by Gemini 3 Pro

import torch
from torch.optim import Optimizer

import torch
from torch.optim import Optimizer

class SGLD(Optimizer):
    def __init__(self, params, lr=1e-4, num_data=640, noise_warmup_steps=300, add_noise=True):
        # We add 'add_noise' to the defaults
        defaults = dict(lr=lr, num_data=num_data, 
                        noise_warmup_steps=noise_warmup_steps, 
                        add_noise=add_noise)
        super(SGLD, self).__init__(params, defaults)
        self.step_count = 0

    @torch.no_grad()
    def step(self, closure=None):
        loss = None
        if closure is not None:
            with torch.enable_grad(): loss = closure()

        self.step_count += 1
        for group in self.param_groups:
            lr = group['lr']
            N = group['num_data']
            # warmup = group['noise_warmup_steps']
            # Check the flag for this specific group
            # should_add_noise = group['add_noise']

            is_sampling = (self.step_count > group['noise_warmup_steps']) and group['add_noise']
            # noise_scale = min(1.0, self.step_count / warmup) if warmup > 0 else 1.0

            for p in group['params']:
                if p.grad is None: 
                    continue

                if is_sampling:
                    p.data.add_(p.grad.data * N, alpha=-lr)
                    noise = torch.randn_like(p.data) * torch.sqrt(torch.tensor(2.0 * lr))
                    p.data.add_(noise)
                else:
                    p.data.add_(p.grad.data, alpha=-lr)
                
                # grad = p.grad.data * N
                # p.data.add_(grad, alpha=-lr)
                # if should_add_noise:
                    # noise = torch.randn_like(p.data) * torch.sqrt(torch.tensor(2.0 * lr)) * noise_scale
                    # p.data.add_(noise)

        return loss


