config:
  _target_: peft.LoraConfig
  task_type: CAUSAL_LM
  inference_mode: false
  init_lora_weights: true #ensures that B weights are init to 0
  r: 8
  lora_alpha: 16
  lora_dropout: 0.0
  exclude_modules: ".*vision_tower.*" #do not fine-tune vision tower for VLMs
  target_modules: 
    - lm_head
    - q_proj
    - v_proj
