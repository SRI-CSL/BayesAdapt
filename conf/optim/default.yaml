max_train_steps: 5000
early_stop_steps: 0
batch_size: 4
warmup_ratio: 0.06
no_decay: ["bias", "LayerNorm.weight"]
weight_decay: 0.0

nll_optimizer:
  _target_: torch.optim.AdamW
  lr: 1.0e-4
  eps: 1.0e-6

nll_scheduler:
  _target_: schedulers.BLoBNLLScheduler
  warmup_ratio: ${optim.warmup_ratio}
  total_steps: ${optim.max_train_steps}

#kl_optimizer:
  #_target_: torch.optim.SGD
  #lr: 0.2

#kl_scheduler:
  #_target_: schedulers.BLoBKLScheduler
  #gamma: 8.0
  #use_exponential: true
  #batch_size: ${optim.batch_size}
  #warmup_ratio: ${optim.warmup_ratio}
  #total_steps: ${optim.max_train_steps}
