{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c5129-388a-4e37-80d1-9c8e036c8920",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a0e4a-a203-4104-ae5d-2616fd6448df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc6996-6c9b-4cb4-b281-b43fcea635dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fname):\n",
    "    try:\n",
    "        with open(fname, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34543b4e-8532-44f5-a00a-7fd141ff92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_with_err(x, y_mean, y_std, linestyle=None, label=None, color='blue', marker='.',ax=None):\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = np.array(x)[sort_idx]\n",
    "    y_mean_sorted = np.array(y_mean)[sort_idx]\n",
    "    y_std_sorted = np.array(y_std)[sort_idx]\n",
    "\n",
    "    y_upper = y_mean_sorted + y_std_sorted\n",
    "    y_lower = y_mean_sorted - y_std_sorted\n",
    "\n",
    "    ax.plot(x_sorted, y_mean_sorted, label=label, linestyle=linestyle,color=color,marker=marker)\n",
    "\n",
    "    ax.fill_between(\n",
    "        x_sorted,\n",
    "        y_lower,\n",
    "        y_upper,\n",
    "        alpha=0.2,\n",
    "        color=color\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91e1b2-4e48-455a-8370-fe58ad6fa8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "int('seed0'[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38ebfb-09a5-45f9-a4ec-37b2f116249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_keys = ['model', 'quant', 'wrapper', 'rank', 'prompt_type', 'dataset']\n",
    "\n",
    "root = '/workspace1/csamplawski/src/BayesAdapt/logs/'\n",
    "json_fnames = glob.glob(f'{root}/**/metrics.json', recursive=True)\n",
    "\n",
    "expdirs = []\n",
    "for fname in json_fnames:\n",
    "    tokens = fname.split('/')\n",
    "    edir = '/'.join(tokens[0:-1])\n",
    "    expdirs.append(edir)\n",
    "expdirs = list(set(expdirs))\n",
    "\n",
    "df = []\n",
    "for edir in expdirs:\n",
    "    tokens = edir.replace(root, '').split('/')\n",
    "    keys = ['model', 'quant', 'wrapper', 'rank', 'prompt_type', 'seed', 'dataset']\n",
    "    row = dict(zip(keys, tokens[1:]))\n",
    "    row['rank'] = int(tokens[4].replace('rank', ''))\n",
    "    row['seed'] = int(tokens[6][-1])\n",
    "    data = load_json(f'{edir}/metrics.json')\n",
    "    row['results'] = data\n",
    "    df.append(row)\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbca4c-87a1-450d-aa88-8edf800bbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df.explode('results').reset_index(drop=True)\n",
    "metrics_df = pd.json_normalize(df_exploded['results']).drop(columns=['seed'])\n",
    "df = pd.concat([df_exploded.drop(columns=['results']), metrics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22443c2-6007-4cf2-951f-a9839814ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df176764-5234-4963-afa0-706f1367d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'winogrande_l'\n",
    "prompt_type = 'instruct'\n",
    "wrapper = 'mle'\n",
    "model = 'Qwen3-8B'\n",
    "\n",
    "q = df.query(f\"model == '{model}' and dataset == '{dataset}' and prompt_type == '{prompt_type}' and wrapper == '{wrapper}'\")#.reset_index()\n",
    "q.groupby(exp_keys)['Brier'].agg(['mean', 'std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3984b7-a6e0-470b-a317-5fd1bb665598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.gca()\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "metrics = ['ACC', 'ECE', 'NLL']\n",
    "\n",
    "dataset = 'winogrande_s'\n",
    "prompt_type = 'instruct'\n",
    "metric = 'ECE'\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    for wrapper in ['mle', 'laplace', 'scalabl', 'tempscale', 'blob','tfb']:\n",
    "        metric_df = df.groupby(exp_keys)[metric].agg(['mean', 'std'])\n",
    "        q = metric_df.query(f\"dataset == '{dataset}' and prompt_type == '{prompt_type}' and wrapper == '{wrapper}'\").reset_index()\n",
    "        ax = plot_with_err(q['model'], q['mean'], q['std'], **style_dict[wrapper], label=wrapper, ax=ax)\n",
    "\n",
    "    ax.set_xlabel('# Parameters (Base + LoRA)')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend(\n",
    "        loc='upper center',          # Anchor point on the legend box itself\n",
    "        bbox_to_anchor=(0.5, -0.15), # (x, y) coordinates relative to the plot axes\n",
    "        ncols=2,       # Forces all items into a single row\n",
    "        frameon=True                # Optional: removes the box border for a cleaner look\n",
    "    )\n",
    "    #ax.set_title(f'Qwen3 Family | Instruct | rank = 8 | {dataset}')\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9aaae8-062d-4a99-9558-61456765734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dict = {\n",
    "    'laplace': {'color': 'black', 'linestyle': '--', 'marker': '.'},\n",
    "    'mle': {'color': 'red', 'linestyle': ':', 'marker': 'v'},\n",
    "    'tempscale': {'color': 'blue', 'linestyle': 'dashdot', 'marker': 'o'},\n",
    "    'blob': {'color': 'purple', 'linestyle': '--', 'marker': 's'},\n",
    "    'scalabl': {'color': 'green', 'linestyle': 'solid', 'marker': '^'},\n",
    "    'tfb': {'color': 'orange', 'linestyle': 'dashdot', 'marker': '^'},\n",
    "    #deepens\n",
    "    #mcdroput\n",
    "    #sgld?\n",
    "    #map\n",
    "    #zeroshot?\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a529b5-4189-4da1-b646-d37cae5f3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.reset_index()['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c5f1b-7882-4e04-b561-739aa81f98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e5a6e-8c8c-4fe3-8d67-db5b484e482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace1/csamplawski/src/BayesAdapt/logs/'\n",
    "json_fnames = glob.glob(f'{root}/**/metrics.json', recursive=True)\n",
    "\n",
    "expdirs = []\n",
    "for fname in json_fnames:\n",
    "    tokens = fname.split('/')\n",
    "    edir = '/'.join(tokens[0:-1])\n",
    "    expdirs.append(edir)\n",
    "expdirs = list(set(expdirs))\n",
    "\n",
    "df = []\n",
    "for edir in expdirs:\n",
    "    if 'scalabl' not in edir:\n",
    "        continue\n",
    "    tokens = edir.replace(root, '').split('/')\n",
    "    print(tokens)\n",
    "    keys = ['model', 'quant', 'wrapper', 'rank', 'prompt_type', 'seed', 'dataset']\n",
    "    row = dict(zip(keys, tokens[1:]))\n",
    "    data = load_json(f'{edir}/metrics.json')\n",
    "    print(row)\n",
    "    print(data)\n",
    "    \n",
    "    data = []\n",
    "    for seed_dir in glob.glob(f'{edir}/*'):\n",
    "        data += load_json(f'{seed_dir}/results.json')\n",
    "\n",
    "        try:\n",
    "            params_info = load_json(f'{seed_dir}/num_params.json')\n",
    "            row['trainable_params'] = params_info['trainable']\n",
    "            row['total_params'] = params_info['total']\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            row['trainable_params'] = data[-1]['num_trainable_params']\n",
    "            row['total_params'] = data[-1]['num_total_params']\n",
    "        except:\n",
    "            pass \n",
    "            \n",
    "    data = pd.DataFrame(data)\n",
    "    row['latency'] = data['latency'].median()\n",
    "    row['peak_memory'] = data['peak_memory'].median()\n",
    "    for metric in ['ACC', 'ECE', 'NLL']:\n",
    "        row[f'{metric}_mean'] = data[metric].mean()\n",
    "        row[f'{metric}_std']  = data[metric].std()\n",
    "    df.append(row)\n",
    "df = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ecea0-c815-49f2-9cb4-9925c76c2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = df['model'].str.contains('Qwen2.5')\n",
    "df = df[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d1bed-e4e7-40a1-858f-f93277ddcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supported values are '-', '--', '-.', ':', 'None', ' ', '', 'solid', 'dashed', 'dashdot', 'dotted'\n",
    "ax = plt.gca()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "metric = 'ACC'\n",
    "dataset = 'winogrande_s'\n",
    "prompt_type = 'instruct'\n",
    "x_key = 'total_params'\n",
    "\n",
    "cond = df['model'].str.contains('Qwen2.5')\n",
    "df[cond]\n",
    "\n",
    "\n",
    "for wrapper in style_dict.keys():\n",
    "    q = df.query(f\"dataset == '{dataset}' and prompt_type == '{prompt_type}' and wrapper == '{wrapper}'\")\n",
    "    ax = plot_with_err(q[x_key], q[f'{metric}_mean'], q[f'{metric}_std'], **style_dict[wrapper], label=wrapper, ax=ax)\n",
    "    \n",
    "ax.grid()\n",
    "ax.set_xlabel('# Parameters (Base + LoRA)')\n",
    "ax.set_ylabel(metric)\n",
    "ax.legend(\n",
    "    loc='upper center',          # Anchor point on the legend box itself\n",
    "    bbox_to_anchor=(0.5, -0.15), # (x, y) coordinates relative to the plot axes\n",
    "    ncols=len(style_dict),       # Forces all items into a single row\n",
    "    frameon=True                # Optional: removes the box border for a cleaner look\n",
    ")\n",
    "ax.set_title(f'Qwen3 Family | Instruct | rank = 8 | {dataset}')\n",
    "#ax.set_xticks(x)\n",
    "#ax.set_xlim(min(x), max(x))\n",
    "#ax.set_xticklabels(q['model'])\n",
    "#ax.set_ylim(0.5,1.0)\n",
    "#q = df.query(\"dataset == 'winogrande_s' and prompt_type == 'base'\")\n",
    "#plt.scatter(q['total_params'], q['ACC_mean'], label='base')\n",
    "\n",
    "#plt.grid()\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb9f03-63f3-498f-8267-0b87b5f62c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Setup your configuration\n",
    "metrics = ['ACC', 'ECE', 'NLL'] \n",
    "dataset = 'ARC-Easy'\n",
    "prompt_type = 'base'\n",
    "x_key = 'total_params'\n",
    "for dataset in ['winogrande_s', 'winogrande_m', 'ARC-Easy', 'ARC-Challenge', 'obqa']:\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    \n",
    "    # 2. Create a figure with 1 row and 3 columns\n",
    "    # figsize is (width, height). Increase width to accommodate 3 plots.\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\n",
    "    \n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        for wrapper in style_dict.keys():\n",
    "            #if wrapper == 'zeroshot':\n",
    "            #    continue\n",
    "            q = df.query(f\"dataset == '{dataset}' and prompt_type == '{prompt_type}' and wrapper == '{wrapper}'\")\n",
    "            \n",
    "            plot_with_err(\n",
    "                q[x_key], \n",
    "                q[f'{metric}_mean'], \n",
    "                q[f'{metric}_std'], \n",
    "                **style_dict[wrapper], \n",
    "                label=wrapper, \n",
    "                ax=ax\n",
    "            )\n",
    "    \n",
    "        ax.grid(True)\n",
    "        ax.set_xlabel('# Parameters (Base + LoRA)')\n",
    "        #ax.set_ylabel(metric)\n",
    "        ax.set_title(metric) # Or more specific title if needed\n",
    "    \n",
    "    # 4. Create the Global Legend\n",
    "    # We grab handles and labels from the first axis (axes[0]) since they are identical across plots\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    \n",
    "    fig.legend(\n",
    "        handles, \n",
    "        labels,\n",
    "        loc='lower center',           # Anchor point of the legend\n",
    "        bbox_to_anchor=(0.5, -0.1),   # (x, y) coordinates relative to the WHOLE FIGURE (0,0 is bottom-left)\n",
    "        ncols=len(style_dict),        # Single row\n",
    "        frameon=True\n",
    "    )\n",
    "    \n",
    "    # 5. formatting\n",
    "    fig.suptitle(f'Qwen3 Family | Instruct | rank = 8 | {dataset}', fontsize=16)\n",
    "    plt.tight_layout() \n",
    "\n",
    "# Adjust layout to make room for the legend at the bottom\n",
    "# (tight_layout calculates spacing, then we shrink the bottom margin slightly)\n",
    "#plt.subplots_adjust(bottom=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8e6d7-dc4a-4620-9575-0f8b3e4ae7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
