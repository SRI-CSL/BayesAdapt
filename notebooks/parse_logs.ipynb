{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a0e4a-a203-4104-ae5d-2616fd6448df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc6996-6c9b-4cb4-b281-b43fcea635dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fname):\n",
    "    try:\n",
    "        with open(fname, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34543b4e-8532-44f5-a00a-7fd141ff92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_err(x, y_mean, y_std, linestyle=None, label=None, color='blue', marker='.',ax=None):\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = np.array(x)[sort_idx]\n",
    "    y_mean_sorted = np.array(y_mean)[sort_idx]\n",
    "    y_std_sorted = np.array(y_std)[sort_idx]\n",
    "\n",
    "    y_upper = y_mean_sorted + y_std_sorted\n",
    "    y_lower = y_mean_sorted - y_std_sorted\n",
    "\n",
    "    ax.plot(x_sorted, y_mean_sorted, label=label, linestyle=linestyle,color=color,marker=marker)\n",
    "\n",
    "    ax.fill_between(\n",
    "        x_sorted,\n",
    "        y_lower,\n",
    "        y_upper,\n",
    "        alpha=0.1,\n",
    "        color=color\n",
    "    )\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_with_err_(x, y_mean, y_std, linestyle=None, label=None, color='blue', marker='.', alpha=0.1, ax=None):\n",
    "    y_upper = y_mean + y_std\n",
    "    y_lower = y_mean - y_std\n",
    "\n",
    "    ax.plot(\n",
    "        x, \n",
    "        y_mean, \n",
    "        label=label, \n",
    "        linestyle=linestyle, \n",
    "        color=color, \n",
    "        marker=marker\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        y_lower,\n",
    "        y_upper,\n",
    "        alpha=alpha,\n",
    "        color=color\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793a5a5-2916-450e-88ec-888e3613b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dict = {\n",
    "    'laplace': {'color': 'black', 'linestyle': '--', 'marker': '.'},\n",
    "    'mle': {'color': 'red', 'linestyle': ':', 'marker': 'v'},\n",
    "    'tempscale': {'color': 'blue', 'linestyle': 'dashdot', 'marker': 'o'},\n",
    "    'blob': {'color': 'purple', 'linestyle': '--', 'marker': 's'},\n",
    "    'scalabl': {'color': 'green', 'linestyle': 'solid', 'marker': '^'},\n",
    "    'tfb': {'color': 'blue', 'linestyle': 'dashdot', 'marker': '^'},\n",
    "    'mcdropout': {'color': 'orange', 'linestyle': 'dashdot', 'marker': 'v'},\n",
    "    #deepens\n",
    "    #mcdroput\n",
    "    #sgld?\n",
    "    #map\n",
    "    #zeroshot?\n",
    "}\n",
    "metric2arrow = {\n",
    "    'ACC': '↑',\n",
    "    'ECE': '↓',\n",
    "    'NLL': '↓',\n",
    "    'Brier': '↓',\n",
    "    'peak_memory': '↓',\n",
    "    'latency': '↓',\n",
    "}\n",
    "\n",
    "wrapper2label = {\n",
    "    'mle': 'MLE',\n",
    "    'blob': 'BLoB',\n",
    "    'scalabl': 'ScalaBL',\n",
    "    'laplace': 'Laplace',\n",
    "    'tfb': 'TFB',\n",
    "    'mcdropout': 'MCDropout',\n",
    "    'tempscale': 'TempScale'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39256e35-e6a1-49c2-bcf1-3e82feaaffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_keys = ['model', 'quant', 'wrapper', 'rank', 'prompt_type', 'dataset', 'num_base', 'num_trainable_params', 'num_total_params']\n",
    "metric_keys = ['ACC', 'ECE', 'NLL', 'Brier', 'peak_memory', 'latency']\n",
    "\n",
    "root = '/workspace1/csamplawski/src/BayesAdapt/logs/'\n",
    "root = '/project/synthesis/bayesadapt/logs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38ebfb-09a5-45f9-a4ec-37b2f116249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fnames = glob.glob(f'{root}/**/id/metrics.json', recursive=True)\n",
    "\n",
    "expdirs = []\n",
    "for fname in json_fnames:\n",
    "    tokens = fname.split('/')\n",
    "    edir = '/'.join(tokens[0:-1])\n",
    "    expdirs.append(edir)\n",
    "expdirs = list(set(expdirs))\n",
    "\n",
    "df = []\n",
    "for edir in expdirs:\n",
    "    tokens = edir.replace(root, '').split('/')\n",
    "    keys = ['model', 'quant', 'wrapper', 'rank', 'prompt_type', 'seed', 'dataset']\n",
    "    row = dict(zip(keys, tokens[1:]))\n",
    "    row['rank'] = int(tokens[4].replace('rank', ''))\n",
    "    row['seed'] = int(tokens[6][-1])\n",
    "    data = load_json(f'{edir}/metrics.json')\n",
    "    row['results'] = data\n",
    "    df.append(row)\n",
    "df = pd.DataFrame(df)\n",
    "df_exploded = df.explode('results').reset_index(drop=True)\n",
    "metrics_df = pd.json_normalize(df_exploded['results']).drop(columns=['seed'])\n",
    "id_df_seeds = pd.concat([df_exploded.drop(columns=['results']), metrics_df], axis=1)\n",
    "id_df = id_df_seeds.groupby(exp_keys)[metric_keys].agg(['mean', 'std'])\n",
    "id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22c6ae-97b1-4be4-8b40-7ddffba07eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12c02c-1456-47b0-ada3-14f346dd1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(df, model=None, dataset=None, wrapper=None, prompt_type='instruct', quant='16bit', rank=8):\n",
    "    query_str = f\"prompt_type == '{prompt_type}' and quant == '{quant}' and rank == {rank}\"\n",
    "    if model is not None:\n",
    "        query_str += f\" and model == '{model}'\"\n",
    "    if dataset is not None:\n",
    "        query_str += f\" and dataset == '{dataset}'\"\n",
    "    if wrapper is not None:\n",
    "        query_str += f\" and wrapper == '{wrapper}'\"\n",
    "    q = df.query(query_str).reset_index()\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae23b3-a0bf-453d-880c-58a658ad848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(id_df_seeds, dataset='slake', prompt_type='vlm', model='Qwen3-VL-2B-Instruct', wrapper='mle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d566607-65ab-4dd0-88af-0bbc111d8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fnames = glob.glob(f'{root}/**/ood/**/metrics.json', recursive=True)\n",
    "expdirs = []\n",
    "for fname in json_fnames:\n",
    "    tokens = fname.split('/')\n",
    "    edir = '/'.join(tokens[0:-1])\n",
    "    expdirs.append(edir)\n",
    "expdirs = list(set(expdirs))\n",
    "\n",
    "df = []\n",
    "for edir in expdirs:\n",
    "    tokens = edir.replace(root, '').split('/')\n",
    "    keys = ['model', 'quant', 'wrapper', 'rank', 'prompt_type', 'seed']\n",
    "    row = dict(zip(keys, tokens[1:-2]))\n",
    "    row['rank'] = int(tokens[4].replace('rank', ''))\n",
    "    row['seed'] = int(tokens[6][-1])\n",
    "    row['dataset'] = tokens[-1]\n",
    "    data = load_json(f'{edir}/metrics.json')\n",
    "    row['results'] = data\n",
    "    df.append(row)\n",
    "df = pd.DataFrame(df)\n",
    "df_exploded = df.explode('results').reset_index(drop=True)\n",
    "metrics_df = pd.json_normalize(df_exploded['results']).drop(columns=['seed'])\n",
    "ood_df = pd.concat([df_exploded.drop(columns=['results']), metrics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946ebbd-dd7c-4669-866c-97b4d4c0fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(25, 5), sharey=False)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "metrics = ['ACC', 'ECE', 'NLL', 'Brier']\n",
    "\n",
    "noise_stds = [0,1,2,4,8,16,32,64,128]\n",
    "\n",
    "dataset = 'slake'\n",
    "prompt_type = 'vlm'\n",
    "quant = '16bit'\n",
    "rank = 8\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    arrow = metric2arrow[metric]\n",
    "    \n",
    "    for wrapper in ['mle', 'scalabl','blob']:\n",
    "        label = wrapper2label[wrapper]\n",
    "        y_mean, y_std = [], []\n",
    "        for std in noise_stds:\n",
    "            if std == 0:\n",
    "                dataset = 'slake'\n",
    "                metric_df = id_df\n",
    "            else:\n",
    "                dataset = f'noisy_slake{std}'\n",
    "                metric_df = ood_df\n",
    "            \n",
    "            metric_vals = metric_df.query(f\"dataset == '{dataset}' and prompt_type == '{prompt_type}' and wrapper == '{wrapper}' and quant == '{quant}' and rank == {rank} and model == 'Qwen3-VL-8B-Instruct'\" ).reset_index()[metric]\n",
    "            y_mean.append(metric_vals.mean())\n",
    "            y_std.append(metric_vals.std())\n",
    "        ax = plot_with_err(noise_stds, y_mean, y_std, **style_dict[wrapper], label=label, ax=ax)\n",
    "        ax.set_xlabel('Noise STD (pixel units)')\n",
    "        \n",
    "    ax.set_ylabel(f\"{metric} ({arrow})\")\n",
    "    ax.legend(\n",
    "        loc='upper center',          # Anchor point on the legend box itself\n",
    "        bbox_to_anchor=(0.5, -0.15), # (x, y) coordinates relative to the plot axes\n",
    "        ncols=2,       # Forces all items into a single row\n",
    "        frameon=True                # Optional: removes the box border for a cleaner look\n",
    "    )\n",
    "    \n",
    "    #ax.set_xscale('log', base=2)\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16a0cf-f8d3-4932-99f0-eb03a2951130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.gca()\n",
    "fig, axes = plt.subplots(1, 4, figsize=(25, 5), sharey=False)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "metrics = ['ACC', 'ECE', 'NLL', 'Brier']\n",
    "\n",
    "dataset = 'slake'\n",
    "prompt_type = 'vlm'\n",
    "quant = '16bit'\n",
    "rank = 8\n",
    "\n",
    "#base_query_str = f\"dataset == '{dataset}' and prompt_type == '{prompt_type}' and quant == '{quant}' and rank == {rank}\"\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    arrow = metric2arrow[metric]\n",
    "    for wrapper in ['mle', 'scalabl', 'blob', 'mcdropout', 'laplace', 'tfb']:\n",
    "        label = wrapper2label[wrapper]\n",
    "        #metric_df = id_df.groupby(exp_keys)[metric].agg(['mean', 'std'])\n",
    "        #query_str = base_query_str + f\" and wrapper == '{wrapper}'\"\n",
    "        #q = id_df.query(query_str).reset_index()\n",
    "        q = query(id_df, prompt_type=prompt_type, wrapper=wrapper, dataset=dataset)\n",
    "        ax = plot_with_err(q['num_base'], q[(metric, 'mean')], q[(metric, 'std')], **style_dict[wrapper], label=label, ax=ax)\n",
    "\n",
    "    ax.set_xlabel('# Parameters (Base + LoRA)')\n",
    "    ax.set_ylabel(f\"{metric} ({arrow})\")\n",
    "    ax.legend(\n",
    "        loc='upper center',          # Anchor point on the legend box itself\n",
    "        bbox_to_anchor=(0.5, -0.15), # (x, y) coordinates relative to the plot axes\n",
    "        ncols=2,       # Forces all items into a single row\n",
    "        frameon=True                # Optional: removes the box border for a cleaner look\n",
    "    )\n",
    "    #ax.set_title(f'Qwen3 Family | {prompt_type} | rank = {rank} | {dataset}')\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a17070-86f1-44a7-af36-24ffd3d48a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.gca()\n",
    "fig, axes = plt.subplots(1, 4, figsize=(25, 5), sharey=False)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "metrics = ['ACC', 'ECE', 'NLL', 'Brier']\n",
    "\n",
    "dataset_sizes = ['xs','s','m','l']\n",
    "x_vals = [160,640,2558,10234]\n",
    "prompt_type = 'instruct'\n",
    "quant = '16bit'\n",
    "model = 'Qwen3-8B'\n",
    "rank = 8\n",
    "\n",
    "base_query_str = f\"model == '{model}' and prompt_type == '{prompt_type}' and quant == '{quant}' and rank == {rank}\"\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    arrow = metric2arrow[metric]\n",
    "    for wrapper in ['mle', 'scalabl', 'blob', 'mcdropout', 'laplace','tfb']:\n",
    "        label = wrapper2label[wrapper]\n",
    "        y_mean, y_std = [], []\n",
    "        for size in dataset_sizes:\n",
    "            query_str = base_query_str + f\" and wrapper == '{wrapper}' and dataset == 'winogrande_{size}'\"\n",
    "            #metric_df = id_df.groupby(exp_keys)[metric].agg(['mean', 'std'])\n",
    "            q = id_df.query(query_str).reset_index()\n",
    "            y_mean.append(q[(metric, 'mean')].item())\n",
    "            y_std.append(q[(metric, 'std')].item())\n",
    "        ax = plot_with_err(x_vals, y_mean, y_std, **style_dict[wrapper], label=label, ax=ax)\n",
    "    ax.grid()\n",
    "    ax.set_ylabel(f\"{metric} ({arrow})\")\n",
    "    ax.set_xlabel('Training Set Size (# of Instances)')\n",
    "    ax.legend(\n",
    "        loc='upper center',          # Anchor point on the legend box itself\n",
    "        bbox_to_anchor=(0.5, -0.15), # (x, y) coordinates relative to the plot axes\n",
    "        ncols=2,       # Forces all items into a single row\n",
    "        frameon=True                # Optional: removes the box border for a cleaner look\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8e6d7-dc4a-4620-9575-0f8b3e4ae7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
